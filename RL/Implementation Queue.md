### K-armed Bandit Implementation
- implement a sample average action value method, conduct a 1000 runs for each value of $\epsilon$, plot average rewards received
- implement the above but for a non stationary problem, demonstrating a sample average's issues when dealing with such a problem
- implement a constant step size in contrast to the sample average method to see its improved performance on a non-stationary problem
- introduce an initial bias! Look at its performance with increased exploration
- implement:
	 ![[Screenshot 2024-10-11 at 11.41.34 AM.png]]
